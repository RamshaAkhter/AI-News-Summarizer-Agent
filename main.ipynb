{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74865867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import Graph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from IPython.display import display, Image as IPImage\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25c57c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38d31af",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['summarizorenv'] =\"utf-8\"\n",
    "\n",
    "#invoke llm\n",
    "llm= ChatOpenAI(\n",
    "    model= \"gpt-4o-mini\",\n",
    "    temperature = 0.5,\n",
    "    api_key = OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    news_query: Annotated[str, \"Input query to extract news search parameters from.\"]\n",
    "    num_searches_remaining: Annotated[int, \"Number of articles to search for.\"]\n",
    "    newsapi_params: Annotated[dict, \"Structured argument for the News API.\"]\n",
    "    past_searches: Annotated[List[dict], \"List of search params already used.\"]\n",
    "    articles_metadata: Annotated[list[dict], \"Article metadata response from the News API\"]\n",
    "    scraped_urls: Annotated[List[str], \"List of urls already scraped.\"]\n",
    "    num_articles_tldr: Annotated[int, \"Number of articles to create TL;DR for.\"]\n",
    "    potential_articles: Annotated[List[dict[str, str, str]], \"Article with full text to consider summarizing.\"]\n",
    "    tldr_articles: Annotated[List[dict[str, str, str]], \"Selected article TL;DRs.\"]\n",
    "    formatted_results: Annotated[str, \"Formatted results to display.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f2755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsApiParams(BaseModel):\n",
    "    q: str = Field(description=\"1-3 concise keyword search terms that are not too specific\")\n",
    "    sources: str =Field(description=\"comma-separated list of sources from: 'abc-news,abc-news-au,associated-press,australian-financial-review,axios,bbc-news,bbc-sport,bloomberg,business-insider,cbc-news,cbs-news,cnn,financial-post,fortune'\")\n",
    "    from_param: str = Field(description=\"date in format 'YYYY-MM-DD' Two days ago minimum. Extend up to 30 days on second and subsequent requests.\")\n",
    "    to: str = Field(description=\"date in format 'YYYY-MM-DD' today's date unless specified\")\n",
    "    language: str = Field(description=\"language of articles 'en' unless specified one of ['ar', 'de', 'en', 'es', 'fr', 'he', 'it', 'nl', 'no', 'pt', 'ru', 'se', 'ud', 'zh']\")\n",
    "    sort_by: str = Field(description=\"sort by 'relevancy', 'popularity', or 'publishedAt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41de60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsState(TypedDict,total=False):\n",
    "    retry_count: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264feeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function generates News API params as per user's question.\"\"\"\n",
    "\n",
    "def generate_newsapi_params(state: GraphState):\n",
    "    today_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    news_query = state.get(\"news_query\", \"\")\n",
    "    num_searches_remaining = state.get(\"num_searches_remaining\", 0)\n",
    "    past_searches = state.get(\"past_searches\") or []\n",
    "\n",
    "    sys_prompt = \"\"\"\n",
    "    Today's date is {today_date}\n",
    "    Create a param dict for the News API on the user query:\n",
    "    {query}\n",
    "\n",
    "    These searches have already been made. Loosen the search terms to get more results.\n",
    "    {past_searches}\n",
    "\n",
    "    Including this one, you have {num_searches_remaining} searches remaining. If this is your last search, use all news resources and 30 days search range.\n",
    "\"\"\"\n",
    "    \n",
    "    sys_msg = sys_prompt.format(\n",
    "        today_date=today_date,\n",
    "        query=news_query,\n",
    "        past_searches=past_searches,\n",
    "        num_searches_remaining=num_searches_remaining\n",
    "    )\n",
    "\n",
    "    llm_with_news_structured_output = llm.with_structured_output(NewsApiParams)\n",
    "\n",
    "    result = llm_with_news_structured_output.invoke([SystemMessage(content=sys_msg)])\n",
    "\n",
    "    params = {\n",
    "        \"q\": result.q,\n",
    "        \"sources\": result.sources,\n",
    "        \"from_param\": result.from_param,\n",
    "        \"to\": result.to,\n",
    "        \"language\": result.language,\n",
    "        \"sort_by\": result.sort_by\n",
    "    }\n",
    "\n",
    "    state[\"newsapi_params\"] = params\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab02427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_article_metadata(state: GraphState):\n",
    "    \"\"\"This gives metadata about the articles\"\"\"\n",
    "    \n",
    "    newsapi_params = state.get(\"newsapi_params\", {})\n",
    "    scraped_urls = state.get(\"scraped_urls\") or []\n",
    "    potential_articles = state.get(\"potential_articles\") or []\n",
    "    past_searches = state.get(\"past_searches\") or []\n",
    "        \n",
    "    # initiate NewsAPI Client\n",
    "    newsapi = NewsApiClient(api_key='e99bd6f587ed4652a89f8e326f082aee')\n",
    "        \n",
    "    # get the articles\n",
    "    articles = newsapi.get_everything(**newsapi_params)\n",
    "    \n",
    "    # add the parameters for the history\n",
    "    past_searches.append(newsapi_params)\n",
    "\n",
    "    new_articles = []\n",
    "        \n",
    "    for article in articles['articles']:\n",
    "        if article['url'] not in scraped_urls and len(potential_articles) + len(new_articles) < 10:\n",
    "            new_articles.append(article)\n",
    "    \n",
    "    state['articles_metadata'] = new_articles\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a914c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_article_text(state: GraphState):\n",
    "    \"\"\"scrape the websites metadata\"\"\"\n",
    "\n",
    "    article_metadata = state.get(\"articles_metadata\") or []\n",
    "\n",
    "    potential_articles = []\n",
    "\n",
    "    # header for scraping\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    for article in article_metadata:\n",
    "        url = article['url']\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            text = soup.get_text(strip=True)\n",
    "\n",
    "            potential_articles.append({\n",
    "                \"title\": article[\"title\"],\n",
    "                \"url\": url,\n",
    "                \"description\": article[\"description\"],\n",
    "                \"text\": text\n",
    "            })\n",
    "\n",
    "            scraped_urls = state.get(\"scraped_urls\") or []\n",
    "            scraped_urls.append(url)\n",
    "            state[\"scraped_urls\"] = scraped_urls\n",
    "\n",
    "    state.get(\"potential_articles\", []).extend(potential_articles)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866ec335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_urls(state: GraphState) -> GraphState:\n",
    "    \"\"\"Based on the article synoses, choose the top-n articles to summarize.\"\"\"\n",
    "    news_query = state.get(\"news_query\", \"\")\n",
    "    num_articles_tldr = state.get(\"num_articles_tldr\", 0)\n",
    "    \n",
    "    # load all processed articles with full text but no summaries\n",
    "    potential_articles = state.get(\"potential_articles\") or []\n",
    "\n",
    "    # format the metadata\n",
    "    formatted_metadata = \"\\n\".join([f\"{article['url']}\\n{article['description']}\\n\" for article in potential_articles])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the user news query:\n",
    "    {news_query}\n",
    "\n",
    "    Reply with a list of strings of up to {num_articles_tldr} relevant urls.\n",
    "    Don't add any urls that are not relevant or aren't listed specifically.\n",
    "    {formatted_metadata}\n",
    "    \"\"\"\n",
    "    result = llm.invoke(prompt).content\n",
    "\n",
    "    # use regex to extract the urls as a list\n",
    "    url_pattern = r'(https?://[^\\s\",]+)'\n",
    "\n",
    "    # Find all URLs in the text\n",
    "    urls = re.findall(url_pattern, result)\n",
    "\n",
    "    # add the selected article metadata to the state\n",
    "    tldr_articles = [article for article in potential_articles if article['url'] in urls]\n",
    "\n",
    "    state[\"tldr_articles\"] = tldr_articles\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e93bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def summarize_articles_parallel(state: GraphState) -> GraphState:\n",
    "    \"\"\"Summarize the articles based on full text.\"\"\"\n",
    "    tldr_articles = state.get(\"tldr_articles\") or []\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Create a * bulleted summarizing tldr for the article:\n",
    "    {text}\n",
    "    Be sure to follow the following format exaxtly with nothing else:\n",
    "    {title}\n",
    "    {url}\n",
    "    * tl;dr bulleted summary\n",
    "    * use bullet points for each sentence\n",
    "    \"\"\"\n",
    "\n",
    "    # iterate over the selected articles and collect summaries synchronously\n",
    "    for i in range(len(tldr_articles)):\n",
    "        text = tldr_articles[i][\"text\"]\n",
    "        title = tldr_articles[i][\"title\"]\n",
    "        url = tldr_articles[i][\"url\"]\n",
    "        # invoke the llm synchronously\n",
    "        result = llm.invoke(prompt.format(title=title, url=url, text=text))\n",
    "        tldr_articles[i][\"summary\"] = result.content\n",
    "\n",
    "    state[\"tldr_articles\"] = tldr_articles\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08d3a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(state: GraphState) -> GraphState:\n",
    "    \"\"\"Format the results for display.\"\"\"\n",
    "    # load a list of past search queries\n",
    "    q = [newsapi_params[\"q\"] for newsapi_params in (state.get(\"past_searches\") or [])]\n",
    "    formatted_results = f\"Here are the top {len(state.get('tldr_articles') or [])} articles based on search terms:\\n{', '.join(q)}\\n\\n\"\n",
    "\n",
    "    # load the summarized articles\n",
    "    tldr_articles = state.get(\"tldr_articles\") or []\n",
    "\n",
    "    # format article tl;dr summaries\n",
    "    tldr_articles = \"\\n\\n\".join([f\"{article['summary']}\" for article in tldr_articles])\n",
    "\n",
    "    # concatenate summaries to the formatted results\n",
    "    formatted_results += tldr_articles\n",
    "\n",
    "    state[\"formatted_results\"] = formatted_results\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef326cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def format_results(state: GraphState) -> GraphState:\\n    \"\"\"Format the results for display.\"\"\"\\n    # load a list of past search queries\\n    q = [newsapi_params[\"q\"] for newsapi_params in state[\"past_searches\"]]\\n    formatted_results = f\"Here are the top {len(state[\\'tldr_articles\\'])} articles based on search terms:\\\\n{\\', \\'.join(q)}\\\\n\\\\n\"\\n\\n    # load the summarized articles\\n    tldr_articles = state[\"tldr_articles\"]\\n\\n    # format article tl;dr summaries\\n    tldr_articles = \"\\\\n\\\\n\".join([f\"{article[\\'summary\\']}\" for article in tldr_articles])\\n\\n    # concatenate summaries to the formatted results\\n    formatted_results += tldr_articles\\n\\n    state[\"formatted_results\"] = formatted_results\\n\\n    return state'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def format_results(state: GraphState) -> GraphState:\n",
    "    \"\"\"Format the results for display.\"\"\"\n",
    "    # load a list of past search queries\n",
    "    q = [newsapi_params[\"q\"] for newsapi_params in state[\"past_searches\"]]\n",
    "    formatted_results = f\"Here are the top {len(state['tldr_articles'])} articles based on search terms:\\\\n{', '.join(q)}\\\\n\\\\n\"\n",
    "\n",
    "    # load the summarized articles\n",
    "    tldr_articles = state[\"tldr_articles\"]\n",
    "\n",
    "    # format article tl;dr summaries\n",
    "    tldr_articles = \"\\\\n\\\\n\".join([f\"{article['summary']}\" for article in tldr_articles])\n",
    "\n",
    "    # concatenate summaries to the formatted results\n",
    "    formatted_results += tldr_articles\n",
    "\n",
    "    state[\"formatted_results\"] = formatted_results\n",
    "\n",
    "    return state'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abcb649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def articles_text_decision(state: GraphState) -> str:\n",
    "    \"\"\"Check results of retrieve_articles_text to determine next step.\"\"\"\n",
    "    \n",
    "    if state.get(\"num_searches_remaining\", 0) == 0:\n",
    "        # if no articles with text were found return END\n",
    "        if len(state.get(\"potential_articles\") or []) == 0:\n",
    "            state[\"formatted_results\"] = \"No articles with text found.\"\n",
    "            return \"END\"\n",
    "        # if some articles were found, move on to selecting the top urls\n",
    "        else:\n",
    "            return \"select_top_urls\"\n",
    "    else:\n",
    "        # if the number of articles found is less than the number of articles to summarize, continue searching\n",
    "        if len(state.get(\"potential_articles\") or []) < state.get(\"num_articles_tldr\", 0):\n",
    "            return \"generate_newsapi_params\"\n",
    "        # otherwise move on to selecting the top urls\n",
    "        else:\n",
    "            return \"select_top_urls\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d093810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph, START, END\n",
    "\n",
    "workflow = Graph()\n",
    "\n",
    "# define nodes\n",
    "workflow.add_node(\"generate_newsapi_params\", generate_newsapi_params)\n",
    "workflow.add_node(\"retrieve_articles_metadata\", retrieve_article_metadata)\n",
    "workflow.add_node(\"retrieve_articles_text\", retrieve_article_text)\n",
    "workflow.add_node(\"select_top_urls\", select_top_urls)\n",
    "workflow.add_node(\"summarize_articles_parallel\", summarize_articles_parallel)\n",
    "workflow.add_node(\"format_results\", format_results)\n",
    "\n",
    "# entry edge: connect START to first node\n",
    "workflow.add_edge(START, \"generate_newsapi_params\")\n",
    "\n",
    "# define edges\n",
    "workflow.add_edge(\"generate_newsapi_params\", \"retrieve_articles_metadata\")\n",
    "workflow.add_edge(\"retrieve_articles_metadata\", \"retrieve_articles_text\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve_articles_text\",\n",
    "    articles_text_decision,\n",
    "    {\n",
    "        # keys here should match possible return values of articles_text_decision(state)\n",
    "        \"generate_newsapi_params\": \"generate_newsapi_params\",\n",
    "        \"select_top_urls\": \"select_top_urls\",\n",
    "        \"END\": END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"select_top_urls\", \"summarize_articles_parallel\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"summarize_articles_parallel\",\n",
    "    lambda state: \"format_results\" if len(state.get(\"tldr_articles\", [])) > 0 else \"END\",\n",
    "    {\n",
    "        \"format_results\": \"format_results\",\n",
    "        \"END\": END\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"format_results\", END)\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15386597",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_workflow(query: str, num_searches_remaining: int = 3, num_articles_tldr: int = 2):\n",
    "    \"\"\"Run the LangGraph workflow and display results.\"\"\"\n",
    "    initial_state = {\n",
    "        \"news_query\": query,\n",
    "        \"num_searches_remaining\": num_searches_remaining,\n",
    "        \"newsapi_params\": {},\n",
    "        \"past_searches\": [],\n",
    "        \"articles_metadata\": [],\n",
    "        \"scraped_urls\": [],\n",
    "        \"num_articles_tldr\": num_articles_tldr,\n",
    "        \"potential_articles\": [],\n",
    "        \"tldr_articles\": [],\n",
    "        \"formatted_results\": \"No articles with text found.\"\n",
    "    }\n",
    "    try:\n",
    "        result = await app.ainvoke(initial_state)\n",
    "        \n",
    "        return result[\"formatted_results\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97c3cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the top 3 articles based on search terms:\n",
      "\n",
      "\n",
      "Apple just joined Nvidia and Microsoft in the $4 trillion club  \n",
      "https://markets.businessinsider.com/news/stocks/apple-stock-price-market-cap-iphone-17-nvidia-microsoft-ai-2025-10  \n",
      "* Apple achieved a market capitalization of $4 trillion for the first time.  \n",
      "* It becomes the third public company to reach this milestone, following Nvidia and Microsoft.  \n",
      "* The surge in Apple’s stock price, reaching around $270, was driven by strong sales of the new iPhone 17.  \n",
      "* The iPhone 17 outsold its predecessor in the US and China during its initial release period.  \n",
      "* Despite the milestone, Apple’s stock has only increased about 7% year to date, amid concerns about its position in the AI sector.  \n",
      "* Nvidia's stock has risen 44% this year, while Microsoft's has increased by 29%.  \n",
      "* Apple reported net sales of $391 billion and net income of $94 billion in its last financial year.  \n",
      "* The company generated over $200 billion from iPhone sales alone.\n",
      "\n",
      "- Apple reported fiscal Q4 earnings, exceeding revenue estimates at $102.5 billion, up 8% year-over-year.\n",
      "- Earnings per share (EPS) also surpassed expectations, growing 13% year-over-year to $1.85.\n",
      "- However, sales in China declined, generating $14.49 billion, below the expected $16.43 billion.\n",
      "- iPhone revenue was $49.02 billion, slightly missing Wall Street's estimate of $49.33 billion.\n",
      "- Following the earnings report, Apple's stock initially dipped 3% but later rose by 5% in after-hours trading.\n",
      "- CFO Kevan Parekh announced plans to increase capital expenditures (capex) with a focus on AI investments.\n",
      "- CEO Tim Cook expressed optimism for a return to growth in China revenue during the holiday quarter, attributing the decline to supply constraints.\n",
      "- Cook highlighted strong reception for the iPhone 17, stating it is resonating well globally.\n",
      "- Apple expects total revenue growth of 10-12% year-over-year for the holiday quarter, aiming for its best quarter ever.\n",
      "- The company reported record services revenue of $28.75 billion, up from $25 billion year-over-year.\n",
      "- Apple faced $1.1 billion in tariff-related costs in Q4, impacting its gross margin.\n",
      "- Cook emphasized ongoing investments in U.S. manufacturing and AI development, alongside a commitment to expand its product roadmap.\n",
      "\n",
      "Americans can't get enough of the iPhone 17 Pro Max  \n",
      "https://www.businessinsider.com/americans-cant-get-enough-of-the-iphone-17-pro-max-2025-10  \n",
      "* iPhone 17 sales in the US and China have outperformed the iPhone 16 by 14% in the first 10 days.  \n",
      "* The iPhone 17 Pro Max has seen the strongest demand among the new lineup in the US.  \n",
      "* The base model iPhone 17 has also sold well, particularly in China.  \n",
      "* Apple's stock rose 4% to a record $262.24 following the sales report.  \n",
      "* The popularity of the Pro Max is attributed to COVID-era shoppers upgrading their devices.  \n",
      "* Major carriers like T-Mobile, Verizon, and AT&T have shifted focus to premium models, enhancing accessibility.  \n",
      "* The iPhone Air is also performing well, outpacing the iPhone 16 Plus in initial sales.  \n",
      "* The iPhone 17 has nearly doubled the sales of the iPhone 16, with sell-out data up 31% year-over-year.  \n",
      "* Analysts highlight the iPhone 17's strong value-for-money proposition as a key driver of sales growth.  \n",
      "* This strong performance is crucial for Apple, as the US and China are significant markets for iPhone sales.\n"
     ]
    }
   ],
   "source": [
    "query = \"Apple Iphone 15\"\n",
    "result=await run_workflow(query, num_articles_tldr=3)\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a967bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizorenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
