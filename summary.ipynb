{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d38dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tavily\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, END\n",
    "# To install: pip install tavily-python\n",
    "from tavily import TavilyClient\n",
    "from IPython.display import display_markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = TavilyClient(os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    search_results: dict  \n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74057c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node 1: Intelligent Web Searcha\n",
    "\n",
    "    Uses Tavily's AI-optimized search to find and process web information.\n",
    "    Behind the scenes: Tavily searches multiple sources, extracts relevant content,\n",
    "    and uses AI to synthesize the information into a coherent answer.\n",
    "    \"\"\"\n",
    "    #print(f\"üîç Searching: {state['question']}\")\n",
    "    client = TavilyClient(os.getenv(\"TAVILY_API_KEY\"))\n",
    "    \n",
    "    \n",
    "    search_results = client.search(\n",
    "        query=state[\"question\"],\n",
    "        max_results=3,        \n",
    "        include_answer=True      \n",
    "    )\n",
    "\n",
    "    return {\"search_results\": search_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: AgentState):\n",
    "    \"\"\"\n",
    "    Node 2: Answer Synthesis and Formatting\n",
    "\n",
    "    Takes the search results from Tavily and formats them into a clean,\n",
    "    user-friendly response with proper source attribution.\n",
    "    \"\"\"\n",
    "    #print(\"ü§ñ Formatting answer...\")\n",
    "\n",
    "    # Extract Tavily's AI-generated answer (the smart synthesis)\n",
    "    ai_answer = state[\"search_results\"].get(\"answer\", \"No answer found\")\n",
    "\n",
    "    # Extract source URLs for transparency and verification\n",
    "    sources = [f\"- {result['title']}: {result['url']}\" \n",
    "              for result in state[\"search_results\"][\"results\"]]\n",
    "\n",
    "    # Combine the intelligent answer with source attribution\n",
    "    final_answer = f\"{ai_answer}\\n\\nSources:\\n\" + \"\\n\".join(sources)\n",
    "\n",
    "    return {\"answer\": final_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_answer(state: AgentState):\n",
    "    \"\"\"\n",
    "    Generate a clean, readable summarized version of the news from the agent state.\n",
    "    This function:\n",
    "      - Extracts search terms and summaries from the state.\n",
    "      - Builds a formatted text summary for display or chat output.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract data safely\n",
    "    query = state.get(\"news_query\", \"General News\")\n",
    "    tldr_articles = state.get(\"tldr_articles\") or []\n",
    "    formatted_results = state.get(\"formatted_results\", \"\")\n",
    "\n",
    "    # If the workflow already produced formatted results, return that directly\n",
    "    if formatted_results and formatted_results != \"No articles with text found.\":\n",
    "        return formatted_results\n",
    "\n",
    "    # If summaries exist, combine them into a readable final summary\n",
    "    if tldr_articles:\n",
    "        summary_lines = [f\"üì∞ **{query.upper()} ‚Äì Summary of Top {len(tldr_articles)} Articles**\\n\"]\n",
    "        for i, article in enumerate(tldr_articles, 1):\n",
    "            title = article.get(\"title\", \"Untitled Article\")\n",
    "            url = article.get(\"url\", \"\")\n",
    "            summary = article.get(\"summary\", \"No summary available.\")\n",
    "            summary_lines.append(f\"**{i}. {title}**\\n{url}\\n{summary}\\n\")\n",
    "        return \"\\n\".join(summary_lines)\n",
    "\n",
    "    # If no summaries exist, fall back to a default message\n",
    "    return f\"No summarized articles found for '{query}'. Please try a different search term.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c447cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def create_agent():\n",
    "    \"\"\"\n",
    "    Build the AI Agent Workflow\n",
    "\n",
    "    This creates a StateGraph where:\n",
    "    - Each node is an independent function that can read/update shared state\n",
    "    - LangGraph handles orchestration, state management, and execution flow\n",
    "    - Easy to extend: just add more nodes and define their connections\n",
    "    \"\"\"\n",
    "    # Create the workflow graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Define our processing nodes\n",
    "    # \"search\" should be your node that gathers information (e.g., search_web)\n",
    "    workflow.add_node(\"search\", search_web)        # Step 1: Gather information  \n",
    "    # \"result\" will format the final answer (uses the format_answer implementation)\n",
    "    workflow.add_node(\"result\", format_answer)     # Step 2: Process and format\n",
    "\n",
    "    # Define the flow of intelligence\n",
    "    workflow.set_entry_point(\"search\")      # Start here\n",
    "    workflow.add_edge(\"search\", \"result\")   # After search, go to answer\n",
    "    workflow.add_edge(\"result\", END)        # After answer, we're done\n",
    "\n",
    "    return workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3eccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.invoke({\"question\":\"todays weather\"})\n",
    "display_markdown(output[\"answer\"], raw=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizorenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
